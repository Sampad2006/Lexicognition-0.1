# Lexicognition: The AI-powered PDF Interviewer

Lexicognition is an AI-powered tool that conducts a technical interview with you based on the content of a PDF document. It uses a Retrieval-Augmented Generation (RAG) pipeline to generate questions, evaluate your answers, and provide feedback with evidence from the source text.

## âœ¨ Features

- [x] **PDF Ingestion**: Loads and processes PDF documents, splitting them into manageable chunks.
- [x] **Vector Storage**: Creates and manages a persistent vector database (ChromaDB) for efficient content retrieval.
- [x] **Conceptual Question Generation**: Uses a Large Language Model (LLM) via Ollama to generate insightful, conceptual questions about the PDF content.
- [x] **Interactive Interview Loop**: Presents questions to the user in a clean command-line interface.
- [x] **AI-Powered Answer Grading**: Evaluates the user's answers for correctness against the document's context.
- [x] **Evidence-Based Feedback**: Provides a score, constructive feedback, and direct quotes from the source document to justify the grade.
- [x] **Modular Architecture**: Components for ingestion, storage, generation, and grading are decoupled, making them easy to modify or replace.

---

## ğŸš€ How to Run

### 1. Prerequisites

- **Python 3.8+**
- **Ollama**: You must have Ollama installed and running.
  - Download from [ollama.ai](https://ollama.ai/)
  - Ensure it's running in the background: `ollama serve`
- **LLM Model**: Pull the required model. We recommend `llama3`.
  ```bash
  ollama pull llama3
  ```

### 2. Installation

Clone the repository and install the required Python packages:

```bash
git clone <repository-url>
cd Lexicognition-0.1
pip install -r requirements.txt
```

### 3. Place Your PDF

Put the PDF you want to be interviewed on in the `data/` directory. By default, the application looks for `data/attention.pdf`.

### 4. Run the Interview

Start the interactive interview session by running `main.py`:

```bash
python main.py
```

- **First Run**: The first time you run it, the application will process the PDF and create a vector database in the `./chroma_db` directory. This may take a few moments.
- **Subsequent Runs**: The application will load the existing database, allowing you to start the interview immediately.

---

## ğŸ”§ Project Structure

```
Lexicognition-0.1/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ attention.pdf              # The source PDF for the interview
â”‚
â”œâ”€â”€ chroma_db/                     # Auto-created vector database
â”‚
â”œâ”€â”€ src/                           # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pdf_ingestion.py           # Phase 1: PDF Ingestion
â”‚   â”œâ”€â”€ vector_store.py            # Phase 2: Vector Storage & Retrieval
â”‚   â”œâ”€â”€ question_generator.py      # Phase 3: Question Generation
â”‚   â””â”€â”€ answer_grader.py           # Phase 4: Answer Grading
â”‚
â”œâ”€â”€ main.py                        # Main application entry point
â”œâ”€â”€ requirements.txt               # Dependencies
â”œâ”€â”€ README.md                      # This file
â””â”€â”€ ARCHITECTURE.md                # Detailed architecture overview
```

---

## ğŸ”„ Pipeline Architecture

The application follows a modular, four-phase RAG pipeline:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Phase 1     â”‚â”€â”€â”€â”€â”€â”€â–¶     Phase 2      â”‚â”€â”€â”€â”€â”€â”€â–¶      Phase 3      â”‚â”€â”€â”€â”€â”€â”€â–¶     Phase 4     â”‚
â”‚    Ingestion    â”‚      â”‚     Storage      â”‚      â”‚     Generator     â”‚      â”‚      Grader     â”‚
â”‚(pdf_ingestion.py)â”‚      â”‚ (vector_store.py)â”‚      â”‚(question_generator.py)â”‚      â”‚ (answer_grader.py) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                        â”‚                        â”‚
  "Load & Chunk PDF"   "Embed & Store Chunks"     "Generate Questions"     "Evaluate Answer"
         â”‚                       â”‚                        â”‚                        â”‚
         â–¼                       â–¼                        â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Text Chunks   â”‚      â”‚   Retriever    â”‚      â”‚    Questions     â”‚      â”‚  Score & Feed- â”‚
â”‚ (w/ Metadata)  â”‚      â”‚   (ChromaDB)   â”‚      â”‚  (from context)  â”‚      â”‚ back (w/ Evi-  â”‚
â”‚                â”‚      â”‚                â”‚      â”‚                  â”‚      â”‚     dence)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

This design allows for easy modification. For more details, see `ARCHITECTURE.md`.
